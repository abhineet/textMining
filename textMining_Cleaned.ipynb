{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import copy\n",
    "from collections import Counter\n",
    "import torch \n",
    "import numpy as np\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    f = open(path, \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    data = []\n",
    "    for l in lines:\n",
    "        labelSplit = l.replace('\\n','').split(' ', 1)\n",
    "        data.append([labelSplit[0], [word.lower() for word in labelSplit[1].split()]])\n",
    "    return data\n",
    "\n",
    "data = read_data('./questions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data, path):\n",
    "    stop_words = []\n",
    "    with open(path) as f:\n",
    "        stop_words = [word for line in f for word in line.split(\",\")]\n",
    "    data_without_stop_words = []\n",
    "    for k, v in data:\n",
    "        words = [t for t in v if t not in stop_words]\n",
    "        data_without_stop_words.append((k, words))\n",
    "    return data_without_stop_words\n",
    "\n",
    "data = remove_stop_words(data, './stop_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(data):\n",
    "    _labels = []\n",
    "    for k,v in data:\n",
    "        _labels.append(k)   \n",
    "    _unique_label = list(set(_labels))\n",
    "    _unique_label_dict = {}\n",
    "    for k,v in enumerate(_unique_label):\n",
    "        _unique_label_dict[v] = k\n",
    "    return _unique_label_dict\n",
    "\n",
    "labels = get_labels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_labels(data, labels):        \n",
    "    cleaned_data = []\n",
    "    for k,v in data:\n",
    "        cleaned_data.append((labels[k],v))\n",
    "        \n",
    "    return np.array(cleaned_data)\n",
    "\n",
    "data = append_labels(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indexed_vocab(data):\n",
    "    vocab = []\n",
    "    for _, sent in data:\n",
    "        for word in sent:\n",
    "            vocab.append(word)\n",
    "    count = Counter(vocab)\n",
    "    count = {w : count[w] for w in count if count[w] >= 2}\n",
    "    vocab = []\n",
    "    for k, v in count.items():\n",
    "        vocab.append(k)\n",
    "    indexed_vocab = {word: idx for idx, word in enumerate(vocab)}\n",
    "    return indexed_vocab\n",
    "def create_vocab(data):\n",
    "    total_words_orig = []\n",
    "    for k,sent in data:\n",
    "        for word in sent:\n",
    "            total_words_orig.append(word)\n",
    "    total_words = list(set(total_words_orig))\n",
    "    total_words_str = ' '.join(total_words)\n",
    "    vocab = set(total_words_str.split()) \n",
    "    word2idx = {word: idx for idx, word in enumerate(vocab)} # create word index\n",
    "    return word2idx\n",
    "word2idx=create_vocab(data)\n",
    "word2idx['#UNK#'] = len(word2idx)\n",
    "indexed_vocab = create_indexed_vocab(data)\n",
    "indexed_vocab['#UNK#'] = len(indexed_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(path, indexed_vocab, embedding_dim=300):\n",
    "    with open(path) as f:\n",
    "        embeddings = np.zeros((len(indexed_vocab), embedding_dim))\n",
    "        for line in f.readlines():\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            index = indexed_vocab.get(word)\n",
    "            if index:\n",
    "                vector = np.array(values[1:], dtype='float32')\n",
    "                embeddings[index] = vector\n",
    "        return torch.from_numpy(embeddings).float()\n",
    "\n",
    "glove_random = load_glove_embeddings('./glove.small.txt', indexed_vocab)\n",
    "glove_pre = load_glove_embeddings('./glove.small.txt', word2idx)\n",
    "embeddings_random = nn.Embedding(glove_random.size(0), glove_random.size(1))\n",
    "embeddings_pretrained = nn.Embedding.from_pretrained(glove_pre, freeze=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    np.random.shuffle(data_copy)\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test = data_copy[:test_set_size]\n",
    "    train = data_copy[test_set_size:]\n",
    "    return train, test\n",
    "\n",
    "train, test = split_train_test(data, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOWClassifier(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size, num_labels):\n",
    "        super(BOWClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size  = hidden_size\n",
    "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(self.input_size, num_labels)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = self.fc1(x)\n",
    "        relu = self.relu(hidden)\n",
    "        output = self.fc2(x)\n",
    "        #output = self.sigmoid(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, indexed_vocab):\n",
    "    pt_tensor= torch.zeros(300, dtype=torch.long)\n",
    "    count = 0\n",
    "    for word in sentence:\n",
    "        count += 1\n",
    "        if word in indexed_vocab:\n",
    "            pt_tensor = torch.add(pt_tensor, embeddings_pretrained(torch.LongTensor([indexed_vocab[word]]))[0])\n",
    "        else:\n",
    "            pt_tensor = torch.add(pt_tensor, embeddings_pretrained(torch.LongTensor([indexed_vocab['#UNK']]))[0])\n",
    "    pt_tensor=torch.div(pt_tensor, count)\n",
    "    return pt_tensor\n",
    "\n",
    "def get_bow_rep(data):\n",
    "    bow_data = []\n",
    "    for label, sent in data:\n",
    "        bow_data.append(make_bow_vector(sent, word2idx).reshape(-1, 300))\n",
    "    return torch.stack(bow_data)\n",
    "        \n",
    "training_set = get_bow_rep(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 300\n",
    "hidden_size = 100\n",
    "num_classes = 51\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0001\n",
    "\n",
    "model = BOWClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 3.7833\n",
      "Epoch [1/50], Loss: 3.6851\n",
      "Epoch [1/50], Loss: 3.6093\n",
      "Epoch [1/50], Loss: 3.8592\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-3ee8525309df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow_vec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \"\"\"\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    permutation = torch.randperm(len(train))\n",
    "    i = 0\n",
    "    for label, question in train[permutation]:\n",
    "        i += 1\n",
    "        optimizer.zero_grad()\n",
    "        bow_vec = make_bow_vector(question, word2idx)\n",
    "        bow_vec = bow_vec.reshape(-1, 300).to(device)\n",
    "        label = torch.LongTensor([label])\n",
    "        label = label.to(device)\n",
    "        output = model(bow_vec)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9403839111328125\n",
      "3.9482805728912354\n",
      "3.9397923946380615\n",
      "3.9321727752685547\n",
      "3.9349703788757324\n",
      "3.9066498279571533\n",
      "3.931408166885376\n",
      "3.9119696617126465\n",
      "3.922466516494751\n",
      "3.918213129043579\n",
      "3.9341979026794434\n",
      "3.927138566970825\n",
      "3.9177258014678955\n",
      "3.934096574783325\n",
      "3.905697822570801\n",
      "3.9190456867218018\n",
      "3.9340808391571045\n",
      "3.8933300971984863\n",
      "3.9105405807495117\n",
      "3.912755012512207\n",
      "3.898181438446045\n",
      "3.911519765853882\n",
      "3.901848554611206\n",
      "3.895630121231079\n",
      "3.9151906967163086\n",
      "3.8991665840148926\n",
      "3.902029037475586\n",
      "3.884066581726074\n",
      "3.89290189743042\n",
      "3.8771679401397705\n",
      "3.901465654373169\n",
      "3.889357089996338\n",
      "3.868481397628784\n",
      "3.881211519241333\n",
      "3.8654448986053467\n",
      "3.8883848190307617\n",
      "3.870983362197876\n",
      "3.881591796875\n",
      "3.870572090148926\n",
      "3.875028610229492\n",
      "3.8696470260620117\n",
      "3.866708993911743\n",
      "3.856107711791992\n",
      "3.861100673675537\n",
      "3.8511111736297607\n",
      "3.8778152465820312\n",
      "3.862687587738037\n",
      "3.8449201583862305\n",
      "3.8469083309173584\n",
      "3.873990535736084\n",
      "3.851212978363037\n",
      "3.855354070663452\n",
      "3.839620351791382\n",
      "3.8436570167541504\n",
      "3.8523900508880615\n",
      "3.821450710296631\n",
      "3.8399457931518555\n",
      "3.8443033695220947\n",
      "3.8319339752197266\n",
      "3.819857597351074\n",
      "3.8267781734466553\n",
      "3.823486328125\n",
      "3.83505916595459\n",
      "3.8426709175109863\n",
      "3.8487954139709473\n",
      "3.8268988132476807\n",
      "3.8183701038360596\n",
      "3.822582721710205\n",
      "3.8273932933807373\n",
      "3.8181591033935547\n",
      "3.8144381046295166\n",
      "3.7996985912323\n",
      "3.820953369140625\n",
      "3.809469223022461\n",
      "3.8057193756103516\n",
      "3.8074679374694824\n",
      "3.793912887573242\n",
      "3.8051137924194336\n",
      "3.814729690551758\n",
      "3.7850916385650635\n",
      "3.7809135913848877\n",
      "3.7873167991638184\n",
      "3.811204195022583\n",
      "3.7859408855438232\n",
      "3.802818536758423\n",
      "3.7852416038513184\n",
      "3.779820203781128\n",
      "3.795651912689209\n",
      "3.790200710296631\n",
      "3.777524471282959\n",
      "3.810811758041382\n",
      "3.772285223007202\n",
      "3.7694883346557617\n",
      "3.744424343109131\n",
      "3.752640962600708\n",
      "3.786536455154419\n",
      "3.7680017948150635\n",
      "3.7482128143310547\n",
      "3.7504630088806152\n",
      "3.7567453384399414\n",
      "3.766281843185425\n",
      "3.763542890548706\n",
      "3.753542900085449\n",
      "3.7720139026641846\n",
      "3.739900827407837\n",
      "3.7338106632232666\n",
      "3.7511706352233887\n",
      "3.756240129470825\n",
      "3.76186466217041\n",
      "3.7790491580963135\n",
      "3.7780213356018066\n",
      "3.7330760955810547\n",
      "3.751742362976074\n",
      "3.763406276702881\n",
      "3.737804651260376\n",
      "3.7711358070373535\n",
      "3.7364864349365234\n",
      "3.7246994972229004\n",
      "3.731083869934082\n",
      "3.741133689880371\n",
      "3.714111328125\n",
      "3.736426591873169\n",
      "3.7288947105407715\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-07f731e79a73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mbatch_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mbatch_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mbatch_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_size = 300\n",
    "hidden_size = 100\n",
    "num_classes = 51\n",
    "num_epochs = 200\n",
    "learning_rate = 0.0001\n",
    "batch_size = 100\n",
    "\n",
    "model = BOWClassifier(input_size, hidden_size, num_classes).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "#training in batches\n",
    "for epoch in range(num_epochs):\n",
    "    permutation = torch.randperm(training_set.size()[0])\n",
    "    for i in range(0, training_set.size()[0], batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        batch_features = training_set[indices]\n",
    "        batch_features = batch_features.reshape(-1, 300).to(device)\n",
    "        batch_labels = torch.LongTensor([label for label, sent in train[indices]]).to(device)\n",
    "\n",
    "        batch_outputs = model(batch_features)\n",
    "        loss = criterion(batch_outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "test_len =len(test)\n",
    "correct=0\n",
    "for label,data in test:\n",
    "    bow_vec = make_bow_vector(data, word2idx)\n",
    "    logprobs = bow(bow_vec)\n",
    "    print(logprobs)\n",
    "    pred = np.argmax(logprobs.data.numpy())\n",
    "    if pred==label:\n",
    "        correct+=1\n",
    "    print('prediction: {}'.format(pred))\n",
    "    print('actual: {}'.format(label))\n",
    "accuracy = correct/test_len\n",
    "print('accuracy: {}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
